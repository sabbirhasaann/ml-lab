import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

# --- Configuration ---
# NOTE: This script assumes the input file is the 500-row dataset generated previously.
ORIGINAL_FILENAME = 'Bangladeshi_Student_Database.xlsx'
DROPPED_FILENAME = 'Data_Dropped_Missing.xlsx'
IMPUTED_FILENAME = 'Data_Imputed_Missing.xlsx'
FINAL_COMPARISON_FILENAME = 'Data_Comparison_Joined.xlsx'
NUM_SAMPLES_FOR_PLOT = 50

# --- Main Script ---
print("--- Starting Data Processing and Comparison Workflow ---")

# --- Step 1: Load the Original Dataset ---
try:
    df_original = pd.read_excel(ORIGINAL_FILENAME)
    print(f"\nSuccessfully loaded '{ORIGINAL_FILENAME}'.")
except FileNotFoundError:
    print(f"\nError: The file '{ORIGINAL_FILENAME}' was not found.")
    print("Please make sure it's in the same folder as this script.")
    exit()

# --- Step 2: Create the 'Dropped Data' File ---
print(f"\n[Strategy A] Creating file with dropped missing values...")
df_dropped = df_original.dropna()
df_dropped.to_excel(DROPPED_FILENAME, index=False)
print(f"-> Successfully saved '{DROPPED_FILENAME}'. It has {len(df_dropped)} rows.")

# --- Step 3: Create the 'Imputed Data' File ---
print(f"\n[Strategy B] Creating file with imputed missing values...")
df_imputed = df_original.copy()
# Calculate mean for Age and median for Exam Marks from the original data
age_mean = df_imputed['Age'].mean()
marks_median = df_imputed['Exam Marks'].median()
# Fill missing values
df_imputed['Age'] = df_imputed['Age'].fillna(age_mean)
df_imputed['Exam Marks'] = df_imputed['Exam Marks'].fillna(marks_median)

# ADDED: Round the imputed ages to the nearest whole number and convert to integer
df_imputed['Age'] = df_imputed['Age'].round(0).astype(int)

df_imputed.to_excel(IMPUTED_FILENAME, index=False)
print(f"-> Successfully saved '{IMPUTED_FILENAME}'. It has {len(df_imputed)} rows.")

# --- Step 4: Normalize Both Datasets Independently ---
print("\nNormalizing both datasets...")
scaler = MinMaxScaler()

# Normalize the dropped dataset
df_dropped_normalized = df_dropped.copy()
df_dropped_normalized[['Age_Normalized_Dropped', 'Marks_Normalized_Dropped']] = scaler.fit_transform(df_dropped_normalized[['Age', 'Exam Marks']])

# Normalize the imputed dataset
df_imputed_normalized = df_imputed.copy()
df_imputed_normalized[['Age_Normalized_Imputed', 'Marks_Normalized_Imputed']] = scaler.fit_transform(df_imputed_normalized[['Age', 'Exam Marks']])
print("-> Normalization complete for both strategies.")

# --- Step 5: Combine Using a 'Left Merge' ---
print(f"\nMerging the two normalized datasets using 'Name' as the key...")
# Select only the necessary columns for the merge
df_dropped_subset = df_dropped_normalized[['Name', 'Age_Normalized_Dropped', 'Marks_Normalized_Dropped']]
# Start with the full imputed dataset and merge the dropped data into it
df_final_comparison = pd.merge(df_imputed_normalized, df_dropped_subset, on='Name', how='left')
print("-> Merge complete.")

# --- Step 6: Save the Final Comparison File ---
df_final_comparison.to_excel(FINAL_COMPARISON_FILENAME, index=False)
print(f"-> Successfully saved final comparison file: '{FINAL_COMPARISON_FILENAME}'")

# --- Step 7: Generate Filtered Comparison Plots ---
print("\nGenerating comparison plots...")

# REVISED LOGIC: First, create a new DataFrame containing only students who
# exist in BOTH the imputed and dropped datasets by removing rows with any nulls.
print(f"Finding students present in both datasets for a direct comparison...")
df_plot_base = df_final_comparison.dropna(subset=['Age_Normalized_Dropped', 'Marks_Normalized_Dropped'])
print(f"-> Found {len(df_plot_base)} students with complete data across both strategies.")
